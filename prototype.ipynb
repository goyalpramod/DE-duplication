{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083210b3-b658-490d-bd77-13b4c140e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "pinecone_api_key = os.environ[\"PINECONE_API_KEY\"]\n",
    "pinecone_env = os.environ[\"PINECONE_ENV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bfa754b-e227-4d12-ad71-f7a04b540a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3611d52f-87c8-4474-8ed5-55b4b0a5642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5b19476-0f3d-40e8-8f6d-cf8390aa8524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Specify the path\n",
    "# path = \"data\"\n",
    "\n",
    "# # Use os.listdir() to list all entries in the specified path\n",
    "# entries = os.listdir(path)\n",
    "\n",
    "# # Print each entry in the specified path\n",
    "# for entry in entries:\n",
    "#     print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98478f93-c562-41c5-a1f9-d3e4ad7da369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from pathlib import Path\n",
    "# from pprint import pprint\n",
    "\n",
    "\n",
    "# file_path=r'data/dummy.json'\n",
    "# data = json.loads(Path(file_path).read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff43a7e-c894-48a3-a33c-0824704c52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29fa0f21-ea22-4798-af5b-89fe4746a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "# # loader = JSONLoader(\n",
    "# #     file_path = r\"data\\dummy.json\",\n",
    "# #     jq_schema='.[]',)\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# loader = TextLoader(r\"data\\dummy.json\")\n",
    "# documents = loader.load()\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "# docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac6e4f8d-b32e-43ea-b402-933dc2e03d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pinecone\n",
    "# from pinecone import Pinecone, ServerlessSpec, PodSpec\n",
    "\n",
    "# pc = Pinecone(\n",
    "#     api_key=pinecone_api_key\n",
    "# )\n",
    "\n",
    "# index_name = \"dimension-demo\"\n",
    "\n",
    "# # First, check if our index already exists. If it doesn't, we create it\n",
    "# if index_name not in pc.list_indexes():\n",
    "#     # we create a new index\n",
    "#     pc.create_index(name=index_name, metric=\"cosine\", dimension=1536, spec = PodSpec(environment=pinecone_env))\n",
    "# # The OpenAI embedding model `text-embedding-ada-002 uses 1536 dimensions`\n",
    "# docsearch = pc.from_documents(docs, embeddings, index_name=index_name)\n",
    "\n",
    "# # if you already have an index, you can load it like this\n",
    "# # docsearch = Pinecone.from_existing_index(index_name, embeddings)\n",
    "\n",
    "# query = \"What is john doing\"\n",
    "# docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ea6701-337c-4652-88b2-9c18edf9e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pinecone import Pinecone, PodSpec\n",
    "\n",
    "# pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "# pc.create_index(\n",
    "#   name=\"pod-index\",\n",
    "#   dimension=1536,\n",
    "#   metric=\"cosine\",\n",
    "#   spec=PodSpec(\n",
    "#     environment=\"gcp-starter\"\n",
    "#   )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "635f8b04-f9b9-4a18-a668-f0413b519802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First, check if our index already exists. If it doesn't, we create it\n",
    "# # if index_name not in pc.list_indexes():\n",
    "# #     # we create a new index\n",
    "# #     pc.create_index(name=index_name, metric=\"cosine\", dimension=1536, spec = PodSpec(environment=pinecone_env))\n",
    "# # The OpenAI embedding model `text-embedding-ada-002 uses 1536 dimensions`\n",
    "# docsearch = pc.from_documents(docs, embeddings, index_name=\"pod-index\")\n",
    "\n",
    "# # if you already have an index, you can load it like this\n",
    "# # docsearch = Pinecone.from_existing_index(index_name, embeddings)\n",
    "\n",
    "# query = \"What is john doing\"\n",
    "# docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c497bc0b-3e46-4352-b677-0bcfff870807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import Pinecone, PodSpec\n",
    "import time\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key,\n",
    "             environment=pinecone_env)\n",
    "\n",
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
    "]\n",
    "\n",
    "index_name = \"pod-index\"\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in existing_indexes:\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "          name= index_name,\n",
    "          dimension=1536,\n",
    "          metric=\"cosine\",\n",
    "          spec=PodSpec(\n",
    "            environment=\"gcp-starter\"\n",
    "          )\n",
    "        )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "968f84b4-6e78-4ca9-86be-7cd3f602f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_community.embeddings import CohereEmbeddings\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from pinecone import Pinecone as PineconeClient\n",
    "import requests\n",
    "load_dotenv()\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Pinecone.from_existing_index(index_name=index_name,\n",
    "                                           embedding=embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b64c2331-b61e-4b61-80c9-cac70c3c8c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Desktop\\work_trial\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "def fetch_url(x):\n",
    "    loader = TextLoader(r\"data\\dummy.txt\")\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(documents)   \n",
    "    return {\"context\": docs, \"question\": x[\"question\"]}\n",
    "\n",
    "# RAG prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# RAG\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4-1106-preview\")\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | RunnableLambda(fetch_url)  # Add this line\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59522663-3ac5-4c96-b6ea-92acdc474f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 9418, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, there are tasks with similar descriptions that suggest they might be duplicates or closely related tasks. Here are the tasks with similar descriptions:\n",
      "\n",
      "1. Task with \"Id\": \"8bd5fcea-3c56-4771-ac41-54321fe98734\" and Task with \"Id\": \"9f8d7c6e-ab7d-4e2c-8c34-56789f0ed3f2\" both have the title \"Database Optimization\" and similar descriptions related to optimizing the database schema and reviewing indexes for effectiveness.\n",
      "\n",
      "2. Task with \"Id\": \"6a8dcef8-3dae-4567-ada4-1a2b3c4d5e6f\" and Task with \"Id\": \"7b8e9d2c-69d1-48a7-b3f1-45678ef9abcd\" both have the title \"Bug Fix on Homepage\" with descriptions indicating issues on the homepage, one related to layout on mobile devices and the other to a JavaScript error in the console.\n",
      "\n",
      "3. Task with \"Id\": \"4e9b7ecd-60ae-4b35-ae8c-22393abcd119\", Task with \"Id\": \"a49b8e7f-c1d2-460e-999d-54e345678bcf\", Task with \"Id\": \"2a3b4c5d-6e7f-8a9b-cdef-1234567890ab\", Task with \"Id\": \"q1w2e3r4-t5y6-u7i8-o9p0-a1s2d3f4g5h6\", and Task with \"Id\": \"r4e3w2q1-t5y6-u7i8-o9p0-a1s2d3f4g5h6\" all have the title \"Implement New Feature\" but with different descriptions indicating various new features to be developed.\n",
      "\n",
      "4. Task with \"Id\": \"eaf7892b-b880-4b57-985c-2a3d4e5678f9\", Task with \"Id\": \"z0y9x8w7-v6u5-t4s3-r2q1-p0o9n8m7l6k5\", and Task with \"Id\": \"i8u7y6t5-r4e3-w2q1-a1s2-d3f4g5h6i7j8\" all have the title \"Perform UAT\" with descriptions that involve coordinating with QA teams or stakeholders for user acceptance testing of new features.\n",
      "\n",
      "While these tasks have similar descriptions, they are not necessarily duplicates as they could represent different aspects of a larger project or different features within the same category. Without additional context, it is not possible to definitively determine if they are duplicates or if they are separate tasks with similar objectives.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"are there any duplicate tasks, tasks which have similar description\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "880039ca-5dc4-4e13-a6fa-5cb173cbcd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag_chain_with_source = RunnableParallel(\n",
    "#     {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "# ).assign(answer=chain)\n",
    "\n",
    "# print(rag_chain_with_source.invoke(\"what is john doing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2833ff8-c245-4dd0-8ccd-a552b2eb6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # upsert the data in \n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# loader = TextLoader(r\"data\\dummy.txt\")\n",
    "# documents = loader.load()\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "# docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# # docsearch = Pinecone.from_documents(docs, embeddings, index_name=index_name)\n",
    "\n",
    "# # if you already have an index, you can load it like this\n",
    "# # docsearch = Pinecone.from_existing_index(index_name, embeddings)\n",
    "\n",
    "# # for batch in dataset.iter_documents(batch_size=100):\n",
    "#     # index.upsert(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57397f48-457d-413a-a600-d8784416c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.upsert(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8739ef1-d9b6-4ef8-8046-bee2936e1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "# docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "015e681e-ebcb-4b6c-8d4b-e5bd0a88501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ccb41219-bfac-456e-a96d-ed6536475400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # More text can embedded and upserted to an existing Pinecone index using the add_texts function\n",
    "\n",
    "# index = pinecone.Index(\"langchain-demo\")\n",
    "# vectorstore = Pinecone(index, embeddings.embed_query, \"text\")\n",
    "\n",
    "# vectorstore.add_texts(\"More text!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08432538-c2a2-41c7-990a-1c3d6bb72e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117eafbf-45f3-4c68-91cf-4c92de1bb3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
